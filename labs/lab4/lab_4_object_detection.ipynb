{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fs1yrbpnQ3DG"
   },
   "source": [
    "# Lab 4 Exploration: Object Detection\n",
    "\n",
    "In this notebook, we will learn how to use the racecar camera to identify objects based on their color and extract the center of these objects.  Next week, we will work toward commanding our robot to move with respect to those objects.\n",
    "\n",
    "Throughout this notebook, **<font style=\"color:red\">text in bold red</font>** indicates a change you must make to the following code block before running it.  **Do not change any other code.**\n",
    "\n",
    "For this lab, run the code one block at a time using ctrl + enter (the control key and the enter key at the same time).  You will want to examine the output of the blocks of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_tQzkfwQ3DS"
   },
   "source": [
    "## 1. Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APFuYrBcQ3DU"
   },
   "source": [
    "First, we will set the file paths, import the Racecar interface, import the necessary libraries for this notebook (`cv`, `numpy`, etc.), and create a Racecar instance.  (Remember, only run this cell once.)  Wait for it to print `racecar created successfully`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nVOQHtnYHJrM"
   },
   "outputs": [],
   "source": [
    "# We will not be using simulation here, so this variable should never change\n",
    "isSimulation = False\n",
    "\n",
    "# Import Python libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from nptyping import NDArray\n",
    "from typing import Any, Tuple, List, Optional\n",
    "\n",
    "# Import Racecar library\n",
    "import sys\n",
    "sys.path.append(1, \"../../library\")\n",
    "import racecar_core\n",
    "import racecar_utils as rc_utils\n",
    "\n",
    "# Create Racecar\n",
    "rc = racecar_core.create_racecar(isSimulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will add some helper functions that will be useful for this lab. Run this cell only once. When it is done it should print `helpers added successfully`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_color_bgr(blue, green, red):\n",
    "    \"\"\"\n",
    "    Displays a color specified in the BGR format.\n",
    "    \"\"\"\n",
    "    rectangle = plt.Rectangle((0,0), 50, 50, fc=(red/255, green/255, blue/255))\n",
    "    plt.gca().add_patch(rectangle)\n",
    "    plt.show()\n",
    "\n",
    "def show_color_hsv(hue, saturation, value):\n",
    "    \"\"\"\n",
    "    Displays a color specified in the HSV format\n",
    "    \"\"\"\n",
    "    # Convert from hsv to rgb\n",
    "    hsv = np.array([[[hue, saturation, value]]], np.uint8)\n",
    "    bgr = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)\n",
    "    \n",
    "    show_color_bgr(bgr[0][0][0], bgr[0][0][1], bgr[0][0][2])\n",
    "\n",
    "def get_mask(image, hsv_lower, hsv_upper):\n",
    "    \"\"\"   \n",
    "    Returns a mask containing all of the areas of image which were between hsv_lower and hsv_upper.\n",
    "    \n",
    "    Args:\n",
    "        image: The image (stored in BGR) from which to create a mask.\n",
    "        hsv_lower: The lower bound of HSV values to include in the mask.\n",
    "        hsv_upper: The upper bound of HSV values to include in the mask.\n",
    "    \"\"\"\n",
    "    # Convert hsv_lower and hsv_upper to numpy arrays so they can be used by OpenCV\n",
    "    hsv_lower = np.array(hsv_lower)\n",
    "    hsv_upper = np.array(hsv_upper)\n",
    "    \n",
    "    image = cv.cvtColor(image, cv.COLOR_RGB2HSV)\n",
    "    mask = cv.inRange(image, hsv_lower, hsv_upper)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "print(\"helpers added successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5x0WjL-sQ3Dh"
   },
   "source": [
    "## 2. Navigating an image\n",
    "Let's take a photo with the car's camera using `rc.camera.get_color_image()` and show it with `rc.display.show_color_image()`.  Both of these functions are specifically provided for the racecar.\n",
    "\n",
    "**<font style=\"color:blue\">Don't make any changes to the block of code.  Run it to take a picture.  Then change what is in front of the car and take a different picture, so you can see that these are live images being taken.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_gm0W_GQ3Di",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize image with a deep copy of the most recent color image captured\n",
    "# by the camera\n",
    "image = rc.camera.get_color_image()\n",
    "\n",
    "# Show the image captured by the camera\n",
    "rc.display.show_color_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wcvl5r0KQ3Dk"
   },
   "source": [
    "Use the coordinates on the output image above to estimate the dimensions of the image.\n",
    "How many rows and columns are there?\n",
    "\n",
    "The image was stored as an array with the name `image`.  You can get the `shape` (dimensions) of an array by writing the array's name, and then adding `.shape` to the end of the name.  Put those hints together to **<font style=\"color:red\">write and run a line of code below that prints the exact dimensions of the image captured above </font>**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXZ8R8DLHJrQ"
   },
   "outputs": [],
   "source": [
    "# TODO: write and run a line of code that prints the shape of the image array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9Q5H3SkHJrQ"
   },
   "source": [
    "What are the three numbers?\n",
    "\n",
    "The color images we retrieve are stored as three dimensional arrays:\n",
    "\n",
    "* **0th dimension**: pixel rows, indexed from top to bottom.\n",
    "* **1st dimension**: pixel columns, indexed from left to right.\n",
    "* **2nd dimension**: pixel color values, ordered blue, green, red, each ranging from 0 (none of that color) to 255 (maximum amount of that color).\n",
    "\n",
    "Let's look at the color values of the middle pixel of our image.\n",
    "\n",
    "**<font style=\"color:blue\">Don't make any changes to the block of code. Predict what color the middle pixel will be. Then run the code to show the color of the middle pixel of the previous image.  Were you right?  If not, try centering a solid-colored object in front of the camera and take another picture.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZWHJiM-2Q3Dl"
   },
   "outputs": [],
   "source": [
    "# Calculate center row and column\n",
    "row = 240\n",
    "col = 320\n",
    "\n",
    "# Extract and print blue, green, and red values\n",
    "blue = image[row][col][0]\n",
    "green = image[row][col][1]\n",
    "red = image[row][col][2]\n",
    "\n",
    "print(\"blue:\", blue)\n",
    "print(\"green:\", green)\n",
    "print(\"red:\", red)\n",
    "\n",
    "# Display this color\n",
    "show_color_bgr(blue, green, red)\n",
    "\n",
    "# Also display the location of the center of the original image.\n",
    "image_copy = image.copy()\n",
    "rc_utils.draw_circle(image_copy, (row, col), rc_utils.ColorBGR.red.value)\n",
    "rc.display.show_color_image(image_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlLYvvF0Q3Dm"
   },
   "source": [
    "**<span style=\"color:blue\">Place a solid-colored object (like your cone) near the edge of the image, but so the camera can still see it. Run the code block below to take a new picture.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2mdfxo_HJrR"
   },
   "outputs": [],
   "source": [
    "# Take image from camera and display it\n",
    "image = rc.camera.get_color_image()\n",
    "rc.display.show_color_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6TGB0LCHJrR"
   },
   "source": [
    "**<span style=\"color:red\">Update `row` and `col` in the following code block to find a pixel that corresponds to your object, and get the RGB values of that pixel.  You can use the axes on the photo above to estimate good pixel coordinates.  What are the B, G, and R values for the object?  Do these B, G, and R values match what you might expect?</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11ZjNao3Q3Dn"
   },
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# TODO: Identify the desired row and column\n",
    "row = 0\n",
    "col = 0\n",
    "#-------------------------------\n",
    "\n",
    "\n",
    "# Extract and print red, green, and blue values\n",
    "blue = image[row][col][0]\n",
    "green = image[row][col][1]\n",
    "red = image[row][col][2]\n",
    "\n",
    "print(\"blue:\", blue)\n",
    "print(\"green:\", green)\n",
    "print(\"red:\", red)\n",
    "\n",
    "# Display this color\n",
    "show_color_bgr(blue, green, red)\n",
    "\n",
    "# Also display the location of the pixel you selected on the original image.\n",
    "image_copy = image.copy()\n",
    "rc_utils.draw_circle(image_copy, (row, col), rc_utils.ColorBGR.red.value, radius=2)\n",
    "rc.display.show_color_image(image_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uQLY1MCQ3Do"
   },
   "source": [
    "## 3. Color Formats\n",
    "By default, the images captured by the camera are stored in the blue-green-red (BGR) color format.  However, when recognizing objects based on their color, it often easier to use the hue-saturation-value (HSV) format because it is more robust to differences in lighting and shading.  The channels in HSV correspond to the following:\n",
    "\n",
    "* **Hue** (0 to 180): The color as it appears on a color wheel, ordered as red-orange-yellow-green-blue-purple-red\n",
    "* **Saturation** (0 to 255): Related to the amount of white in the color. 0 is pure white, and 255 is the pure color without any white added.\n",
    "* **Value** (0 to 255): Related to the amount of black in the color. 0 is pure black, and 255 is the pure color without any black added.\n",
    "\n",
    "While saturation and value vary with lighting, hue will remain mostly the same regardless of lighting.  By focusing on the hue of the object we are attempting to detect, we can find it even in different lighting environments.\n",
    "\n",
    "We can use the following widgets to experiment with different color values in the BGR and HSV formats.  You will need to run the code blocks to get the widgets to appear.\n",
    "\n",
    "<b><font style=\"color:blue\">For both formats, find the values which produce the following colors:\n",
    "- green\n",
    "- orange\n",
    "\n",
    "You should have 4 sets of values at the end, one set for each of the 2 colors with each of the 2 color schemes.\n",
    "</font></b>\n",
    "\n",
    "Try to represent the same shade with both color schemes.  For consistency, you can try to match the provided green and orange cones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kOlm7HxtQ3Do",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BGR color\n",
    "widgets.interact(\n",
    "    show_color_bgr,\n",
    "    blue=widgets.IntSlider(0, 0, 255, continuous_update=False),\n",
    "    green=widgets.IntSlider(0, 0, 255, continuous_update=False),\n",
    "    red=widgets.IntSlider(0, 0, 255, continuous_update=False),\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lbt4_TkWQ3Dq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HSV color\n",
    "widgets.interact(\n",
    "    show_color_hsv,\n",
    "    hue=widgets.IntSlider(0, 0, 180, continuous_update=False),\n",
    "    saturation=widgets.IntSlider(255, 0, 255, continuous_update=False),\n",
    "    value=widgets.IntSlider(255, 0, 255, continuous_update=False),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yoDmtQ72HJrT"
   },
   "source": [
    "## CHECKPOINT:  Write your HSV values on your board.  Talk to another team and compare your HSV values with their HSV values.  How are your answers similar or different? Do both teams' answers make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NyazUj1Q3Dr"
   },
   "source": [
    "## 4. Masks\n",
    "Let's work on identifying an object in the car's field of view based on its color.  Specifically, we will isolate the portions of an image which fall within a certain color range by defining upper and lower HSV bounds. We will use that to create a *mask* - a special type of image which tells us which parts of an image to include and which parts to exclude.\n",
    "\n",
    "When we apply a mask to an image, only some parts of the original image will show up in the output image.  (How does this compare to when a person wears a mask or partial mask?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JUCIE7dQ3Ds"
   },
   "source": [
    "Let's isolate the colored cone(s) in an image.\n",
    "\n",
    "\n",
    "<b><font style=\"color:blue\">\n",
    "Place one bright green cone in the car's line of sight and take a picture by running the following block of code.\n",
    "</font></b>\n",
    "\n",
    "If you do not have a green cone, you can use any object with a distinct color, but we recommend using the green cone first if you have one.  We recommend avoiding red as your first color. (Why?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WsVh1EGdQ3Dt"
   },
   "outputs": [],
   "source": [
    "image = rc.camera.get_color_image()\n",
    "rc.display.show_color_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vDLJLYjQ3Du"
   },
   "source": [
    "Next, we will use the `rc_utils.find_contours()` function to create a mask containing just the cone(s).  \n",
    "\n",
    "We will choose which pixels to include or exclude from the mask based on the HSV values of the pixels.  If the HSV values lie between `hsv_lower` and `hsv_upper`, the pixels will be included.  We specify `hsv_lower` and `hsv_upper` as 3 numbers each, in the order H, S, V.\n",
    "\n",
    "When you first receive this code, `hsv_lower` is (0, 0, 0) and `hsv_upper` is (180, 255, 255).  All possible HSV values lie between these values of `hsv_lower` and `hsv_upper`, so the mask will contain the entire image.  **<font style=\"color:red\">Tune the values of `hsv_lower` and `hsv_upper` until the mask only includes the cone.  </font>**  \n",
    "\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "* Use the HSV color widget from the Color Formats section above to visualize HSV colors.\n",
    "* Saturation and value vary a lot with lighting, but hue will remain mostly constant for a given object. Try using a wide range for value and saturation but a tight range for hue.\n",
    "* If you have both masked and unmasked areas, the area that will be included will appear yellow in the output image, and the part to be excluded will appear blue/purple.  (If the whole image is included, as you initially received it, the whole mask will appear blue/purple.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7FJWjKZ3Q3Du"
   },
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# TODO: change these bounds\n",
    "hsv_lower = (0, 0, 0) # (hue, saturation, value)\n",
    "hsv_upper = (180, 255, 255) # (hue, saturation, value)\n",
    "#-------------------------------\n",
    "\n",
    "# Given color bounds, create a mask\n",
    "mask = get_mask(image, hsv_lower, hsv_upper)\n",
    "\n",
    "# Display the mask\n",
    "rc.display.show_color_image(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "giajvA7UQ3Dw"
   },
   "source": [
    "We can use this mask as a filter for our original image to only keep portions that were between `hsv_lower` and `hsv_upper`.  The portions we include will appear in the new image as they did in the original image.  The portions that we exclude will appear black in the new image, instead of showing the content they used to contain.\n",
    "\n",
    "<b><font style=\"color:blue\">\n",
    "Run the next cell and confirm that your colored cone still appears the correct color, while the background is replaced by solid black.  If it doesn't, tune your HSV values again to adjust the mask.\n",
    "</font></b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bMA_1kCwQ3Dw"
   },
   "outputs": [],
   "source": [
    "masked_image = cv.bitwise_and(image, image, mask=mask)\n",
    "rc.display.show_color_image(masked_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P86WTRNjHJrV"
   },
   "source": [
    "## CHECKPOINT:  Compare your values for `hsv_lower` and `hsv_upper` with another team's.  If your objects are the same color (e.g., both green cones), are your values similar?  If your objects are different colors (e.g., green cone and orange cone), do the other team's values make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2iF0OHmQ3Dx"
   },
   "source": [
    "## 5. Finding Contours\n",
    "\n",
    "Now that we have a mask, we can create outlines around each object in the mask. We will use these outlines to identify the largest object and calculates its size and position. These outlines are often referred to as *contours*, which is what we will be calling them from now on.\n",
    "\n",
    "The following steps have been done for you in the code.\n",
    "\n",
    "First, we use the function `rc_utils.find_contours()` to create a list of contours around each distinct object in the mask.  There may be more than one contour if there are multiple cones in the image or if there are other objects that have a similar color to the cone(s).  Next, we use `rc_utils.get_largest_contour()` to find the largest contour and draw it on the image.\n",
    "\n",
    "<b><font style=\"color:blue\">\n",
    "Run the next cell and confirm that you see a green outline surrounding the closest cone in your image.  If you want, you can coordinate with another team to borrow their cone so you can confirm that only the larger contour is outlined when multiple contours are present.\n",
    "</font></b>\n",
    "\n",
    "Note: If you want to use a new image, you will need to re-run the code blocks starting from Section 4 to take an image, compute the mask, and then compute contours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sS-4b5xGQ3D0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find the largest contour\n",
    "contours = rc_utils.find_contours(mask)\n",
    "largest_contour = rc_utils.get_largest_contour(contours)\n",
    "\n",
    "# Draw it on the image and display the updated image\n",
    "image_copy = np.copy(image)\n",
    "if (largest_contour is not None):\n",
    "    rc_utils.draw_contour(image_copy, largest_contour)\n",
    "    rc.display.show_color_image(image_copy)\n",
    "else:\n",
    "    print(\"No contours found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVs1Hbr4Q3D2"
   },
   "source": [
    "One advantage of using contours is that it allows us to easily calculate the center of an object. We'll now calculate the center point of the cone, then draw a dot at that point.\n",
    "\n",
    "<b><font style=\"color:blue\">\n",
    "Run the next cell and confirm that you see a small cyan (light blue) dot in the middle of the visible part of your cone.\n",
    "</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OFlL6-baQ3D2"
   },
   "outputs": [],
   "source": [
    "# Find the center of this contour if it exists\n",
    "if (largest_contour is not None):\n",
    "    center = rc_utils.get_contour_center(largest_contour)\n",
    "    \n",
    "    # Draw a circle at the contour center\n",
    "    rc_utils.draw_circle(image_copy, center)\n",
    "    rc.display.show_color_image(image_copy)\n",
    "else:\n",
    "    print(\"No contours found, so no center point to find\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtrUP_AXHJrW"
   },
   "source": [
    "## 6. Image Cropping\n",
    "\n",
    "Often, the car will think it sees objects in the background that have the same color as the object you are trying to detect. This can be for many reasons. Here are a few:\n",
    "- There is some colored lighting (e.g., caused by a sunset) that makes an object look a different color than it usually does.\n",
    "- There's a reflective surface in the background, and the car is seeing a reflection of your object.\n",
    "\n",
    "One way to avoid picking up on these extra detections is to only look at the ground in front of us while driving, instead of looking at the whole image. (For example, we might use this strategy if we are trying to follow a piece of tape on the ground, and don't need to look at the sky.)\n",
    "\n",
    "**<font style=\"color:red\">With your cone near the edge of the camera image, edit `top_left_corner` and `bottom_right_corner` until the image is roughly centered around the cone. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2GKzXRbHJrW"
   },
   "outputs": [],
   "source": [
    "# Take image from camera and display it\n",
    "image = rc.camera.get_color_image()  # Returns a color image in BGR\n",
    "\n",
    "#-------------------------------\n",
    "# TODO: CROP IMAGE.  Coordinate is (row, column)\n",
    "top_left_corner = (0,0)\n",
    "bottom_right_corner = (480,640)\n",
    "#-------------------------------\n",
    "\n",
    "image = rc_utils.crop(image, top_left_corner, bottom_right_corner)\n",
    "rc.display.show_color_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChSkCMPjHJrW"
   },
   "source": [
    "**<font style=\"color:red\">Then, copy your HSV bounds from before, create a mask, and demonstrate that the masking process still works on the cropped image.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLfx0q8tHJrW"
   },
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# TODO: copy your HSV bounds from before\n",
    "hsv_lower = (0, 0, 0) # (hue, saturation, value)\n",
    "hsv_upper = (180, 255, 255) # (hue, saturation, value)\n",
    "\n",
    "# TODO: include the line of code that uses the HSV\n",
    "#       bounds to create a mask.\n",
    "\n",
    "\n",
    "#-------------------------------\n",
    "\n",
    "# Display the mask\n",
    "rc.display.show_color_image(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECB_13ZTHJrX"
   },
   "source": [
    "**<font style=\"color:blue\">Finally, run the next code block to see the detected center of the cone in the cropped image. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nJc-VOLSHJrX"
   },
   "outputs": [],
   "source": [
    "# Find the largest contour\n",
    "contours = rc_utils.find_contours(mask)\n",
    "largest_contour = rc_utils.get_largest_contour(contours)\n",
    "\n",
    "# Draw it on the image\n",
    "image_copy = np.copy(image)\n",
    "rc_utils.draw_contour(image_copy, largest_contour)\n",
    "\n",
    "# Get the center of the contour\n",
    "center = rc_utils.get_contour_center(largest_contour)\n",
    "\n",
    "# Draw a circle at the contour center\n",
    "rc_utils.draw_circle(image_copy, center)\n",
    "rc.display.show_color_image(image_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgU1lERRHJrX"
   },
   "source": [
    "## CHECKPOINT:  Show your output to an instructor/TA and be ready to explain what is going on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<font style=\"color:purple\">NEED \"Challenge\" exercises here for those who finish quickly?</font>**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
